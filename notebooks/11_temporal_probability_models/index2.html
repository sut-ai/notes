---
layout: content
metadata: notebooks_11_temporal_probability_models_metadata
colab: https://colab.research.google.com/github/sut-ai/notes/blob/master/notebooks/11_temporal_probability_models/index2.ipynb/index.ipynb
---

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Chain Rule and HMMs</strong></p>
<p>Look at the bellow model.</p>
<p><img alt="" height="73" src="https://i.ibb.co/Fmm8KV4/image-2021-05-13-171737.png" width="150"/></p>
<p>From the chain rule, <em>every</em> joint distribution over can be written as:</p>
<p><img alt="" height="31" src="https://i.ibb.co/WKws4RT/image-2021-05-13-171904.png" width="401"/></p>
<p>And because we have bellow terms:</p>
<p><img alt="" height="11" src="https://i.ibb.co/WsD3TpP/image-2021-05-13-172512.png" width="414"/></p>
<p>After simplifications we have:</p>
<p><img alt="" height="12" src="https://i.ibb.co/LtxSLby/image-2021-05-13-172748.png" width="425"/></p>
<p>We can see some of real HMM examples:</p>
<ul>
<li>Speech recognition HMMs:
<ul style="list-style-type: square;">
<li>Observations are acoustic signals (continuous valued)</li>
<li>States are specific positions in specific words (so, tens of thousands)</li>
</ul>
</li>
<li>Machine translation HMMs:
<ul>
<li>Observations are words (tens of thousands)</li>
<li>States are translation options</li>
</ul>
</li>
<li>Robot tracking:
<ul>
<li>Observations are range readings (continuous)</li>
<li>States are positions on a map (continuous)</li>
</ul>
</li>
</ul>
<p> </p>
<p><strong>Filtering/Monitoring</strong></p>
<p>First of all we define B<sub>t</sub>(x) = P(X<sub>t</sub> | E<sub>1</sub>, …, E<sub>t</sub>) as the belief state and it shows our prediction from next hidden variable according to our observations from start to now. we start from first belief state B<sub>0</sub>(X) in an initial setting (usually uniform) and as time passes or we get observations, we update the value of B<sub>t</sub>(X). In other words we have a vector with lentgh of number of hidden variables and each cell of this vector has our prediction of it's real value. we name this task of tracking the distribution B<sub>t</sub>(X) (actually B(X)) over time "Flitering" or "Monitoring".</p>
<p> </p>
<p><strong>Example: Robot Localization</strong></p>
<p>Robot localization is the process of determining where a mobile robot is located with respect to its environment. Localization is one of the most fundamental competencies required by an autonomous robot as the knowledge of the robot's own location is an essential precursor to making decisions about future actions. In a typical robot localization scenario, a map of the environment is available and the robot is equipped with sensors that observe the environment as well as monitor its own motion. in this example sensor model can read in which directions there is a wall, never more than 1 mistake and motion model may not execute action with small probability. as mentioned earlier B<sub>0</sub>(X) assigned uniform.</p>
<p><img alt="" height="145" src="https://i.ibb.co/tJhcWhd/image-2021-05-13-181644.png" width="188"/></p>
<p>Bellow tape shows the colour of each probability for all cells. for example in t=0 each cell has equal probability.</p>
<p><img alt="" height="157" src="https://i.ibb.co/n3k41fH/image-2021-05-13-183502.png" width="188"/></p>
<p>Cells those are compatible with our evidence from sensors has most probability to be the real place of robot. lighter grey cells are possible to get the reading, but less likely b/c required 1 mistake. white cells need more mistakes so theirs probability is near to zero.</p>
<p>After skipping some states we have:</p>
<p><img alt="" height="165" src="https://i.ibb.co/r0gPnrP/image-2021-05-13-182944.png" width="180"/></p>
<p>And then:</p>
<p><img alt="" height="169" src="https://i.ibb.co/xfjNNPZ/image-2021-05-13-183107.png" width="183"/></p>
<p>In this state the answer is approximately certain.</p>
<p> </p>
<p><strong>Passage of Time</strong></p>
<p>If in the current state we have the belief B(X<sub>t</sub>)=P(X<sub>t</sub>|e<sub>1:t</sub>). then after one time step passes for P(X<sub>t+1</sub>|e<sub>1:t</sub>) we have:</p>
<p><img height="127" src="https://i.ibb.co/82Ddcrx/image-2021-05-13-184443.png" width="224"/></p>
<p>We know P(X<sub>t+1</sub>|e<sub>1:t</sub>) isn't what we defined as B<sub>t+1</sub>(X) so we name it B'(X<sub>t+1</sub>) and we have:</p>
<p><img alt="" height="55" src="https://i.ibb.co/7nDpTj8/image-2021-05-13-184849.png" width="159"/></p>
<p>We name the first part P(X'|x<sub>t</sub>) as transition and say beliefs get “pushed” through the transitions.</p>
<p> </p>
<p><strong>Example: Passage of Time</strong></p>
<p>In this model as time passes, uncertainty about the answer accumulates and increases.</p>
<p><img alt="" height="120" src="https://i.ibb.co/c8LdYxD/image-2021-05-13-185716.png" width="600"/></p>
<p> </p>
<p><strong>Observation</strong></p>
<p>Now we want to affect the observation in our prediction about next value of hidden variable.</p>
<p><img alt="" height="40" src="https://i.ibb.co/tPQR0ty/Picture3.jpg" width="222"/></p>
<p>And now in each state after observation we have:</p>
<p><img alt="" height="93" src="https://i.ibb.co/VCwxHrS/Picture3.jpg" width="288"/></p>
<p>We named the second part P(X<sub>t+1</sub>|e<sub>1:t</sub>) as belief and say beliefs get “reweighted” by likelihood of evidence.</p>
<p>** Unlike passage of time, we have to renormalize.</p>
<p> </p><p><strong>Example: Observation</strong></p>
<p>In this model as we get observations, beliefs get reweighted and uncertainty about the answer decreases.</p>
<p><img alt="" height="125" src="https://i.ibb.co/6nd0B29/image-2021-05-13-192007.png" width="600"/></p>
<p> </p><p><strong>Example: Weather HMM</strong></p>
<p>In this example we want to predict the weather by looking our friend, is he come with umbrella or not. First day we use a uniform distribution but after first day, in each day we compute B' and then after observation of umbrella compute B for that day and do this for each day to decreasing the uncertainty.</p>
<p><img alt="" height="186" src="https://i.ibb.co/0V2XBGZ/Picture3.jpg" width="520"/></p>
<p> </p>
<p><strong>The Forward Algorithm</strong></p>
<p>We are given evidence at each time and want to know:</p>
<p><img alt="" height="21" src="https://i.ibb.co/F406RmD/image-2021-05-13-193937.png" width="188"/></p>
<p>We can derive the following updates:</p>
<p><img alt="" height="148" src="https://i.ibb.co/x1PZ6vV/Picture3.jpg" width="310"/></p>
<p>We can normalize as we go if we want to have P(x|e) at each time step, or just once at the end. But which is better?</p>
<p> </p>
<p><strong>Online Belief Updates</strong></p>
<p>Every time step, we start with current P(X | evidence)</p>
<p>We update for time:</p>
<p><img alt="" height="32" src="https://i.ibb.co/WFCXKL0/image-2021-05-13-194923.png" width="343"/></p>
<p>We update for evidence:</p>
<p><img alt="" height="21" src="https://i.ibb.co/0KYTpLz/image-2021-05-13-195017.png" width="342"/></p><p> </p>
<p><strong>Particle Filtering</strong></p>
<p>In some problems |X| is too big for exact computing or even for storing B(X), so it's almost impossible to use previous algorithms. For example when X is continous. In this situations we must use approximate inference.</p>
<p>In this algorithm we track just samples of X not all values and name this samples particles. Time per step is linear in the number of samples but number needed may be large enough and in memory should store list of particles not states.</p>
<p><img alt="" height="179" src="https://i.ibb.co/2gXcttw/Picture3.jpg" width="491"/></p>
<p>Now represent P(X) by a list of N particles and P(x) approximate by number of particles with value of x. We know generally N&lt;&lt;|X| so many x may have p(x)=0 and this isn't good event. For solving this issue we must use more particles to achieve more accuracy.(For now assume all particles has the same weight)</p>
<p> </p>
<p><strong>Elapse Time</strong></p>
<p>Each particle moved by transition model to it's next position.</p>
<p><img alt="" height="26" src="https://i.ibb.co/0fXJqqt/image-2021-05-13-213911.png" width="230"/></p>
<p>Just like the prior sampling, each sample frequency reflect the transtition probabilities. </p>
<p>As mentioned earlier for closing to exact values, must use enough samples.</p>
<p><img alt="" height="175" src="https://i.ibb.co/mGSKHnC/Picture3.jpg" width="490"/></p>
<p> </p>
<p><strong>Observe</strong></p>
<p>Just like the likelihood weighting, each sample's  probabilities computed based on the evidence.(As before, the probabilities don’t sum to one, since all have been down weighted and need to normalizing)</p>
<p><img alt="" height="206" src="https://i.ibb.co/t4Nvcnj/Picture3.jpg" width="398"/></p>
<p> </p>
<p><strong>Resample</strong></p>
<p>We use resampling (N times) intead of tracking weighted samples in this way choose from our weighted sample distribution (i.e. draw with replacement). This method is equivalent to renormalizing the distribution.</p>
<p>And now the update is complete for this time step, continue with the next one.</p>
<p><img alt="" height="135" src="https://i.ibb.co/ZNdKB8k/Picture3.jpg" width="407"/></p>
<p> </p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span> 
</pre></div>
</div>
</div>
</div>
</div>
